<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Publications - Anna Rogers</title>
<meta name="description" content="Anna Rogers’ personal page">



<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Anna Rogers">
<meta property="og:title" content="Publications">
<meta property="og:url" content="https://annargrs.github.io/publications/">













<link rel="canonical" href="https://annargrs.github.io/publications/">













<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Anna Rogers Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



<!--bibtex hack-->
<script>
function showBibtex(bibDiv) {
  console.log(bibDiv);
  var x = document.getElementById(bibDiv);
  if (x.style.display === "none" || x.style.display === '') {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
</script>
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!--link rel="icon" type="image/png" href="/assets/images/logo-3col.png"-->

<link href="https://fonts.googleapis.com/css?family=Roboto&display=swap" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Oswald&display=swap" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="/assets/css/academicons.min.css"/>
<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">Anna Rogers</a>
        <ul class="visible-links">
<li class="masthead__menu-item">
              <a href="/">Home</a>
            </li>
<li class="masthead__menu-item">
              <a href="/publications/">Publications</a>
            </li>
<li class="masthead__menu-item">
              <a href="/talks/">Talks</a>
            </li>
<li class="masthead__menu-item">
              <a href="/teaching/">Teaching</a>
            </li>
<li class="masthead__menu-item">
              <a href="/lab/">Lab</a>
            </li>
<li class="masthead__menu-item">
              <a href="/service/">Service</a>
            </li>
<li class="masthead__menu-item">
              <a href="/outreach/">Outreach</a>
            </li>
<li class="masthead__menu-item">
              <a href="https://hackingsemantics.xyz/year-archive/">Blog</a>
            </li>
</ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/aro.jpg" alt="" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse"><i class="fa fa-bars" aria-hidden="true"></i>  Profile links</button>
    <ul class="author__urls social-icons">
      

      
        
          
            <li><a href="https://pure.itu.dk/en/persons/anna-rogers" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-university" aria-hidden="true"></i> IT University of Copenhagen</a></li>
          
        
          
            <li><a href="https://scholar.google.com/citations?user=5oCYOE0AAAAJ&amp;hl=en" rel="nofollow noopener noreferrer"><i class="ai ai-google-scholar ai" aria-hidden="true"></i> Google Scholar</a></li>
          
        
          
            <li><a href="https://www.semanticscholar.org/author/Anna-Rogers/145046059" rel="nofollow noopener noreferrer"><i class="ai ai-semantic-scholar ai" aria-hidden="true"></i> Semantic Scholar</a></li>
          
        
          
            <li><a href="https://orcid.org/0000-0002-4845-4023" rel="nofollow noopener noreferrer"><i class="ai ai-orcid ai" aria-hidden="true"></i> ORCID</a></li>
          
        
      


      

      
        <li>
          <a href="mailto:arog@itu.dk">
            <meta itemprop="email" content="arog@itu.dk">
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/annargrs" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      
        <li>
          <a href="https://www.linkedin.com/in/annargrs" itemprop="sameAs" rel="nofollow noopener noreferrer">
            <i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  


<!-- stolen from here:
https://www.gungorbudak.com/blog/2017/12/08/tags-cloud-sorted-by-post-count-for-jekyll-blogs-without-plugins/
-->
<!--div class="tag-cloud">








</div-->



  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Publications">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Publications
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Total pubs: 52</p>

<ul>
  <li>
<img class="emoji" title=":ledger:" alt=":ledger:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d2.png" height="20" width="20"> Journal articles: 3</li>
  <li>
<img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> Conference and workshop articles: 31, including 18 in <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">  top-tier venues</li>
  <li>
<img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20"> Edited volumes: 12</li>
  <li>
<img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20"> Preprints and other non-peer-reviewed publications (excluding blog articles): 5</li>
</ul>

<p>Bibliometrics: <a href="https://scholar.google.com/citations?user=5oCYOE0AAAAJ&amp;hl=en">h-index 24, 5.9K+ citations on Google Scholar</a></p>

<h2 id="2024">2024</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="puccetti2024ainewscontentfarms">Puccetti, G., <b>Rogers, A.</b>, Alzetta, C., Dell’Orletta, F., &amp; Esuli, A. (2024). AI ‘News’ Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian. In L.-W. Ku, A. Martins, &amp; V. Srikumar (Eds.), <i>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i> (pp. 15312–15338). Bangkok, Thailand: Association for Computational Linguistics.</span>

    
    

    
    <img class="emoji" title=":trophy:" alt=":trophy:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3c6.png" height="20" width="20"> <b>Area Chair Award</b>
    

    
    <button class="btn--info" onclick="showBibtex('puccetti2024ainewscontentfarms_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2024.acl-long.817'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="puccetti2024ainewscontentfarms_abs">Large Language Models (LLMs) are increasingly used as ‘content farm’ models (CFMs), to generate synthetic text that could pass for real news articles. This is already happening even for languages that do not have high-quality monolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on English, on as little as 40K Italian news articles, is sufficient for producing news-like texts that native speakers of Italian struggle to identify as synthetic.We investigate three LLMs and three methods of detecting synthetic texts (log-likelihood, DetectGPT, and supervised classification), finding that they all perform better than human raters, but they are all impractical in the real world (requiring either access to token likelihood information or a large dataset of CFM texts). We also explore the possibility of creating a proxy CFM: an LLM fine-tuned on a similar dataset to one used by the real ‘content farm’. We find that even a small amount of fine-tuning data suffices for creating a successful detector, but we need to know which base LLM is used, which is a major challenge.Our results suggest that there are currently no practical methods for detecting synthetic news-like texts ‘in the wild’, while generating them is too easy. We highlight the urgency of more NLP research on this problem.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="rogers2024position"><b>Rogers, A.</b>, &amp; Luccioni, S. (2024). Position: Key Claims in LLM Research Have a Long Tail of Footnotes. <i>Forty-first International Conference on Machine Learning</i>.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('rogers2024position_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://openreview.net/forum?id=M2cwkGleRL'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="rogers2024position_abs">Much of the recent discourse within the ML community has been centered around Large Language Models (LLMs), their functionality and potential – yet not only do we not have a working definition of LLMs, but much of this discourse relies on claims and assumptions that are worth re-examining. We contribute a definition of LLMs, critically examine five common claims regarding their properties (including ’emergent properties’), and conclude with suggestions for future research directions and their framing.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="insights-2024-insights">Tafreshi, S., Akula, A., Sedoc, J., Drozd, A., <b>Rogers, A.</b>, &amp; Rumshisky, A. (Eds.). (2024). <i>Proceedings of the Fifth Workshop on Insights from Negative Results in NLP</i>. Mexico City, Mexico: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2024.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    

    
    <img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20">
    

    

    

    <span id="KuznetsovAfzalEtAl_2024_What_Can_Natural_Language_Processing_Do_for_Peer_Review">Kuznetsov, I., Afzal, O. M., Dercksen, K., Dycke, N., Goldberg, A., Hope, T., … Gurevych, I. (2024). <i>What Can Natural Language Processing Do for Peer Review?</i> arXiv.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KuznetsovAfzalEtAl_2024_What_Can_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://arxiv.org/abs/2405.06563'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="KuznetsovAfzalEtAl_2024_What_Can_abs">The number of scientific articles produced every year is growing rapidly. Providing quality control over them is crucial for scientists and, ultimately, for the public good. In modern science, this process is largely delegated to peer review – a distributed procedure in which each submission is evaluated by several independent experts in the field. Peer review is widely used, yet it is hard, time-consuming, and prone to error. Since the artifacts involved in peer review – manuscripts, reviews, discussions – are largely text-based, Natural Language Processing has great potential to improve reviewing. As the emergence of large language models (LLMs) has enabled NLP assistance for many new tasks, the discussion on machine-assisted peer review is picking up the pace. Yet, where exactly is help needed, where can NLP help, and where should it stand aside? The goal of our paper is to provide a foundation for the future efforts in NLP for peer-reviewing assistance. We discuss peer review as a general process, exemplified by reviewing at AI conferences. We detail each step of the process from manuscript submission to camera-ready revision, and discuss the associated challenges and opportunities for NLP assistance, illustrated by existing work. We then turn to the big challenges in NLP for peer review as a whole, including data acquisition and licensing, operationalization and experimentation, and ethical issues. To help consolidate community efforts, we create a companion repository that aggregates key datasets pertaining to peer review. Finally, we issue a detailed call for action for the scientific community, NLP and AI researchers, policymakers, and funding bodies to help bring the research in NLP for peer review forward. We hope that our work will help set the agenda for research in machine-assisted scientific quality control in the age of AI, within the NLP community and beyond.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="rogers-etal-2024-narrativetime-dense"><b>Rogers, A.</b>, Karpinska, M., Gupta, A., Lialin, V., Smelkov, G., &amp; Rumshisky, A. (2024). NarrativeTime: Dense Temporal Annotation on a Timeline. In N. Calzolari, M.-Y. Kan, V. Hoste, A. Lenci, S. Sakti, &amp; N. Xue (Eds.), <i>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</i> (pp. 12053–12073). Torino, Italia: ELRA and ICCL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('rogers-etal-2024-narrativetime-dense_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2024.lrec-main.1054'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="rogers-etal-2024-narrativetime-dense_abs">For the past decade, temporal annotation has been sparse: only a small portion of event pairs in a text was annotated. We present NarrativeTime, the first timeline-based annotation framework that achieves full coverage of all possible TLINKs. To compare with the previous SOTA in dense temporal annotation, we perform full re-annotation of the classic TimeBankDense corpus (American English), which shows comparable agreement with a signigicant increase in density. We contribute TimeBankNT corpus (with each text fully annotated by two expert annotators), extensive annotation guidelines, open-source tools for annotation and conversion to TimeML format, and baseline results.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    

    

    
    <img class="emoji" title=":ledger:" alt=":ledger:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d2.png" height="20" width="20">
    

    

    <span id="SavcisensEliassi-RadEtAl_2024_Using_sequences_of_life-events_to_predict_human_lives">Savcisens, G., Eliassi-Rad, T., Hansen, L. K., Mortensen, L. H., Lilleholt, L., <b>Rogers, A.</b>, … Lehmann, S. (2024). Using Sequences of Life-Events to Predict Human Lives. <i>Nature Computational Science</i>, <i>4</i>(1), 43–56.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('SavcisensEliassi-RadEtAl_2024_Using_sequences_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'Here we represent human lives in a way that shares structural similarity to language, and we exploit this similarity to adapt natural language processing techniques to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on a comprehensive registry dataset, which is available for Denmark across several years, and that includes information about life-events related to health, education, occupation, income, address and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space, showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to discover potential mechanisms that impact life outcomes as well as the associated possibilities for personalized interventions.'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="SavcisensEliassi-RadEtAl_2024_Using_sequences_abs">https://arxiv.org/pdf/2306.03009.pdf</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="jimenezsanchez2024copycats">Jiménez-Sánchez, A., Avlona, N.-R., Juodelyte, D., Sourget, T., Vang-Larsen, C., <b>Rogers, A.</b>, … Cheplygina, V. (2024). Copycats: the many lives of a publicly available medical imaging dataset. <i>The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track</i>.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('jimenezsanchez2024copycats_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://openreview.net/forum?id=X4KImMSIRq'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="jimenezsanchez2024copycats_abs">Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data’s public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets’ context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare.</div>
    
</div>



    
</li>
</ol>

<h2 id="2023">2023</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    

    

    
    <img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20">
    

    

    

    <span id="LuccioniRogers_2023_Mind_your_Language_Model_FactChecking_LLMs_and_their_Role_in_NLP_Research_and_Practice">Luccioni, A. S., &amp; <b>Rogers, A.</b> (2023). <i>Mind Your Language (Model): Fact-Checking LLMs and Their Role in NLP Research and Practice</i>. arXiv (under review).</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('LuccioniRogers_2023_Mind_your_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://arxiv.org/abs/2308.07120'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="LuccioniRogers_2023_Mind_your_abs">Much of the recent discourse within the NLP research community has been centered around Large Language Models (LLMs), their functionality and potential – yet not only do we not have a working definition of LLMs, but much of this discourse relies on claims and assumptions that are worth re-examining. This position paper contributes a definition of LLMs, explicates some of the assumptions made regarding their functionality, and outlines the existing evidence for and against them. We conclude with suggestions for research directions and their framing in future work.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    

    
    <img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20">
    

    

    

    <span id="rogers-etal-2023-report"><b>Rogers, A.</b>, Karpinska, M., Boyd-Graber, J., &amp; Okazaki, N. (2023). Program Chairs’ Report on Peer Review at ACL 2023. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('rogers-etal-2023-report_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-long.report'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="rogers-etal-2023-report_abs">We present a summary of the efforts to improve conference peer review that were implemented at ACL’23. This includes work with the goal of improving review quality, clearer workflow and decision support for the area chairs, as well as our efforts to improve paper-reviewer matching for various kinds of non- mainstream NLP work, and improve the overall incentives for all participants of the peer review process. We present analysis of the factors affecting peer review, identify the most problematic issues that the authors complained about, and provide suggestions for the future chairs. We hope that publishing such reports would (a) improve transparency in decision-making, (b) help the people new to the field to understand how the *ACL conferences work, (c) provide useful data for the future chairs and workshop organizers, and also academic work on peer review, and (d) provide useful context for the final program, as a source of information for meta-research on the structure and trajectory of the field of NLP.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="acl-2023-frontmatter"><b>Rogers, A.</b>, Boyd-Graber, J., &amp; Okazaki, N. (Eds.). (2023). <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-long.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="acl-2023-short-frontmatter"><b>Rogers, A.</b>, Boyd-Graber, J., &amp; Okazaki, N. (Eds.). (2023). <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-short.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="findings-2023-findings-association"><b>Rogers, A.</b>, Boyd-Graber, J., &amp; Okazaki, N. (Eds.). (2023). <i>Findings of the Association for Computational Linguistics: ACL 2023</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.findings-acl.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="PiktusAkikiEtAl_2023_ROOTS_Search_Tool_Data_Transparency_for_LLMs">Piktus, A., Akiki, C., Villegas, P., Laurençon, H., Dupont, G., Luccioni, S., … <b>Rogers, A.</b> (2023). The ROOTS Search Tool: Data Transparency for LLMs. <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)</i>, 304–314. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('PiktusAkikiEtAl_2023_ROOTS_Search_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-demo.29'">PDF</button>
    

    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://huggingface.co/spaces/bigscience-data/roots-search'">DEMO</button>
    

    

    
    <div class="abstract" id="PiktusAkikiEtAl_2023_ROOTS_Search_abs">ROOTS is a 1.6TB multilingual text corpus developed for the training of BLOOM, currently the largest language model explicitly accompanied by commensurate data governance efforts. In continuation of these efforts, we present the ROOTS Search Tool: a search engine over the entire ROOTS corpus offering both fuzzy and exact search capabilities. ROOTS is the largest corpus to date that can be investigated this way. The ROOTS Search Tool is open-sourced and available on Hugging Face Spaces: https://huggingface.co/spaces/bigscience-data/roots-search. We describe our implementation and the possible use cases of our tool.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="repl4nlp-2023-representation">Can, B., Mozes, M., Cahyawijaya, S., Saphra, N., Kassner, N., Ravfogel, S., … Voita, L. (Eds.). (2023). <i>Proceedings of the 8th Workshop on Representation Learning for NLP (RepL4NLP 2023)</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.repl4nlp-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="insights-2023-insights">Tafreshi, S., Akula, A., Sedoc, J., Drozd, A., <b>Rogers, A.</b>, &amp; Rumshisky, A. (Eds.). (2023). <i>The Fourth Workshop on Insights from Negative Results in NLP</i>. Dubrovnik, Croatia: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
</ol>

<h2 id="2022">2022</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    

    

    
    <img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20">
    

    

    

    <span id="ScaoFanEtAl_2022_BLOOM_176BParameter_OpenAccess_Multilingual_Language_Model">Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., … Wolf, T. (2022). <i>BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</i>. arxiv.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('ScaoFanEtAl_2022_BLOOM_176BParameter_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://arxiv.org/abs/2211.05100'">PDF</button>
    

    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://huggingface.co/bigscience/bloom'">DEMO</button>
    

    

    
    <div class="abstract" id="ScaoFanEtAl_2022_BLOOM_176BParameter_abs">Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="LaurenconSaulnierEtAl_2022_BigScience_ROOTS_Corpus_6TB_Composite_Multilingual_Dataset">Laurençon, H., Saulnier, L., Wang, T., Akiki, C., Villanova del Moral, A., Le Scao, T., … Jernite, Y. (2022). The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset. <i>Thirty-Sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</i>. Presented at the New Orleans, United States. New Orleans, United States.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('LaurenconSaulnierEtAl_2022_BigScience_ROOTS_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://openreview.net/forum?id=UoEw6KigkUn'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="LaurenconSaulnierEtAl_2022_BigScience_ROOTS_abs">As language models grow ever larger, the need for large-scale high-quality text datasets has never been more pressing, especially in multilingual settings. The BigScience workshop, a 1-year international and multidisciplinary initiative, was formed with the goal of researching and training large language models as a values-driven undertaking, putting issues of ethics, harm, and governance in the foreground. This paper documents the data creation and curation efforts undertaken by BigScience to assemble the Responsible Open-science Open-collaboration Text Sources (ROOTS) corpus, a 1.6TB dataset spanning 59 languages that was used to train the 176-billion-parameter BigScience Large Open-science Open-access Multilingual (BLOOM) language model. We further release a large initial subset of the corpus and analyses thereof, and hope to empower large-scale monolingual and multilingual modeling projects with both the data and the processing tools, as well as stimulate research around this large multilingual corpus.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    

    

    
    <img class="emoji" title=":ledger:" alt=":ledger:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d2.png" height="20" width="20">
    

    

    <span id="RogersGardnerEtAl_2021_QA_Dataset_Explosion_Taxonomy_of_NLP_Resources_for_Question_Answering_and_Reading_Comprehension"><b>Rogers, A.</b>, Gardner, M., &amp; Augenstein, I. (2022). QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension. <i>ACM CSUR</i>. https://doi.org/https://doi.org/10.1145/3560260</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersGardnerEtAl_2021_QA_Dataset_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://arxiv.org/abs/2107.12708'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="RogersGardnerEtAl_2021_QA_Dataset_abs">Alongside huge volumes of research on deep learning models in NLP in the recent years, there has been also much work on benchmark datasets needed to track modeling progress. Question answering and reading comprehension have been particularly prolific in this regard, with over 80 new datasets appearing in the past two years. This study is the largest survey of the field to date. We provide an overview of the various formats and domains of the current resources, highlighting the current lacunae for future work. We further discuss the current classifications of “reasoning types" in question answering and propose a new taxonomy. We also discuss the implications of over-focusing on English, and survey the current monolingual resources for other languages and multilingual resources. The study is aimed at both practitioners looking for pointers to the wealth of existing data, and at researchers working on new resources.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="thorn-jakobsen-rogers-2022-factors">Thorn Jakobsen, T., &amp; <b>Rogers, A.</b> (2022). What Factors Should Paper-Reviewer Assignments Rely On? Community Perspectives on Issues and Ideals in Conference Peer-Review. <i>Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</i>, 4810–4823. Seattle, United States: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('thorn-jakobsen-rogers-2022-factors_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.naacl-main.354'">PDF</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/terne/Paper-Reviewer-Matching-Surveys'">DATA</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.naacl-main.354.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id="thorn-jakobsen-rogers-2022-factors_abs">Both scientific progress and individual researcher careers depend on the quality of peer review, which in turn depends on paper-reviewer matching. Surprisingly, this problem has been mostly approached as an automated recommendation problem rather than as a matter where different stakeholders (area chairs, reviewers, authors) have accumulated experience worth taking into account. We present the results of the first survey of the NLP community, identifying common issues and perspectives on what factors should be considered by paper-reviewer matching systems. This study contributes actionable recommendations for improving future NLP conferences, and desiderata for interpretable peer review assignments.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="JerniteNguyenEtAl_2022_Data_Governance_in_Age_of_Large-Scale_Data-Driven_Language_Technology">Jernite, Y., Nguyen, H., Biderman, S., <b>Rogers, A.</b>, Masoud, M., Danchev, V., … Mitchell, M. (2022). Data Governance in the Age of Large-Scale Data-Driven Language Technology. <i>2022 ACM Conference on Fairness, Accountability, and Transparency</i>, 2206–2222. https://doi.org/10.1145/3531146.3534637</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('JerniteNguyenEtAl_2022_Data_Governance_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://dl.acm.org/doi/10.1145/3531146.3534637'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="JerniteNguyenEtAl_2022_Data_Governance_abs">The recent emergence and adoption of Machine Learning technology, and specifically of Large Language Models, has drawn attention to the need for systematic and transparent management of language data. This work proposes an approach to global language data governance that attempts to organize data management amongst stakeholders, values, and rights. Our proposal is informed by prior work on distributed governance that accounts for human values and grounded by an international research collaboration that brings together researchers and practitioners from 60 countries. The framework we present is a multi-party international governance structure focused on language data, and incorporating technical and organizational tools needed to support its work.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="insights-2022-insights">Tafreshi, S., Sedoc, J., <b>Rogers, A.</b>, Drozd, A., Rumshisky, A., &amp; Akula, A. (Eds.). (2022). <i>Proceedings of the Third Workshop on Insights from Negative Results in NLP</i>. Dublin, Ireland: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="repl4nlp-2022-representation">Gella, S., He, H., Majumder, B. P., Can, B., Giunchiglia, E., Cahyawijaya, S., … Dyer, C. (Eds.). (2022). <i>Proceedings of the 7th Workshop on Representation Learning for NLP</i>. Dublin, Ireland: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.repl4nlp-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="ray-choudhury-etal-2022-machine">Ray Choudhury, S., <b>Rogers, A.</b>, &amp; Augenstein, I. (2022). Machine Reading, Fast and Slow: When Do Models ’Understand’ Language? <i>Proceedings of the 29th International Conference on Computational Linguistics</i>, 78–93. Gyeongju, Republic of Korea.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('ray-choudhury-etal-2022-machine_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.coling-1.8'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="ray-choudhury-etal-2022-machine_abs">Two of the most fundamental issues in Natural Language Understanding (NLU) at present are: (a) how it can established whether deep
    learning-based models score highly on NLU benchmarks for the ’right’ reasons; and (b) what those reasons would even be.
    We investigate the behavior of reading comprehension models with respect to two linguistic ’skills’:
    coreference resolution and comparison. We propose a definition for the reasoning steps expected from a system that would be ’reading slowly’,
    and compare that with the behavior of five models of the BERT family of various sizes, observed through saliency scores and counterfactual explanations.
    We find that for comparison (but not coreference) the systems based on larger encoders are more likely to rely on the ’right’ information, but even
    they struggle with generalization, suggesting that they still learn specific lexical patterns rather than the general principles of comparison.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="puccetti2022">Puccetti, G., <b>Rogers, A.</b>, Drozd, A., &amp; Dell’Orletta, F. (2022). Outliers Dimensions that Disrupt Transformers Are Driven by Frequency. <i>Findings of EMNLP 2022</i>. Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('puccetti2022_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.findings-emnlp.93/'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/gpucce/outliersvsfreq/tree/main'">CODE</button>
    

    

    

    

    

    

    

    
    <div class="abstract" id="puccetti2022_abs">Transformer-based language models are known to display anisotropic behavior: the token embeddings are not homogeneously spread in space,
  but rather accumulate along certain directions. A related recent finding is the outlier phenomenon: the parameters in the final element of Transformer
  layers that consistently have unusual magnitude in the same dimension across the model, and significantly degrade its performance if disabled.
  We replicate the evidence for the outlier phenomenon and we link it to the geometry of the embedding space. Our main finding is that in both BERT and RoBERTa
  the token frequency, known to contribute to anisotropicity, also contributes to the outlier phenomenon. In its turn, the outlier phenomenon contributes to the
  ’vertical’ self-attention pattern that enables the model to focus on the special tokens. We also find that, surprisingly, the outlier effect on the model
   performance varies by layer, and that variance is also related to the correlation between outlier magnitude and encoded token frequency.</div>
    
</div>



    
</li>
</ol>

<h2 id="2021">2021</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="insights-2021-insights">Sedoc, J., <b>Rogers, A.</b>, Rumshisky, A., &amp; Tafreshi, S. (Eds.). (2021). <i>Proceedings of the Second Workshop on Insights from Negative Results in NLP</i>. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="BhargavaDrozdEtAl_2021_Generalization_in_NLI_Ways_Not_To_Go_Beyond_Simple_Heuristics">Bhargava, P., Drozd, A., &amp; <b>Rogers, A.</b> (2021). Generalization in NLI: Ways (Not) To Go Beyond Simple Heuristics. <i>Proceedings of the Second Workshop on Insights from Negative Results in NLP</i>, 125–135. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('BhargavaDrozdEtAl_2021_Generalization_in_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.insights-1.18'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/prajjwal1/generalize_lm_nli'">CODE</button>
    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.insights-1.18.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id="BhargavaDrozdEtAl_2021_Generalization_in_abs">Much of recent progress in NLU was shown to be due to models’ learning dataset-specific heuristics. We conduct a case study of generalization in NLI (from MNLI to the adversarially constructed HANS dataset) in a range of BERT-based architectures (adapters, Siamese Transformers, HEX debiasing), as well as with subsampling the data and increasing the model size. We report 2 successful and 3 unsuccessful strategies, all providing insights into how Transformer-based models learn to generalize.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="RogersBaldwinEtAl_2021_Just_What_do_You_Think_Youre_Doing_Dave_Checklist_for_Responsible_Data_Use_in_NLP"><b>Rogers, A.</b>, Baldwin, T., &amp; Leins, K. (2021). Just What Do You Think You’re Doing, Dave? A Checklist for Responsible Data Use in NLP. <i>Findings of the Association for Computational Linguistics: EMNLP 2021</i>, 4821–4833. Punta Cana, Dominican Republic: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersBaldwinEtAl_2021_Just_What_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-emnlp.414/'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-emnlp.414.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id="RogersBaldwinEtAl_2021_Just_What_abs">A key part of the NLP ethics movement is responsible use of data, but exactly what that means or how it can be best achieved remain unclear. This position paper discusses the core legal and ethical principles for collection and sharing of textual data, and the tensions between them. We propose a potential checklist for responsible data (re-)use that could both standardise the peer review of conference submissions, as well as enable a more in-depth view of published research across the community. Our proposal aims to contribute to the development of a consistent standard for data (re-)use, embraced across NLP conferences.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="repl4nlp-2021-representation"><b>Rogers, A.</b>, Calixto, I., Vulić, I., Saphra, N., Kassner, N., Camburu, O.-M., … Shwartz, V. (Eds.). (2021). <i>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</i>. Online: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.repl4nlp-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="GonzalezRogersEtAl_2021_On_Interaction_of_Belief_Bias_and_Explanations">González, A. V., <b>Rogers, A.</b>, &amp; Søgaard, A. (2021). On the Interaction of Belief Bias and Explanations. <i>Findings of ACL-IJCNLP 2021</i>, 2930–2942. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('GonzalezRogersEtAl_2021_On_Interaction_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-acl.259'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="GonzalezRogersEtAl_2021_On_Interaction_abs">A myriad of explainability methods have been proposed in recent years, but there is little consensus on how to evaluate them. While automatic metrics allow for quick benchmarking, it isn’t clear how such metrics reflect human interaction with explanations. Human evaluation is of paramount importance, but previous protocols fail to account for belief biases affecting human performance, which may lead to misleading conclusions. We provide an overview of belief bias, its role in human evaluation, and ideas for NLP practitioners on how to account for it. For two experimental paradigms, we present a case study of gradient-based explainability introducing simple ways to account for humans’ prior beliefs: models of varying quality and adversarial examples. We show that conclusions about the highest performing methods change when introducing such controls, pointing to the importance of accounting for belief bias in evaluation.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="KovalevaKulshreshthaEtAl_2021_BERT_Busters_Outlier_Dimensions_that_Disrupt_Transformersa">Kovaleva, O., Kulshreshtha, S., <b>Rogers, A.</b>, &amp; Rumshisky, A. (2021). BERT Busters: Outlier Dimensions That Disrupt Transformers. <i>Findings of ACL-IJCNLP 2021</i>, 3392–3405. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KovalevaKulshreshthaEtAl_2021_BERT_Busters_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-acl.300'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://text-machine-lab.github.io/blog/2021/busters'">BLOG</button>
    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-acl.300.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id="KovalevaKulshreshthaEtAl_2021_BERT_Busters_abs">Multiple studies have shown that Transformers are remarkably robust to pruning. Contrary to this received wisdom, we demonstrate that pre-trained Transformer encoders are surprisingly fragile to the removal of a very small number of features in the layer outputs (&lt;0.0001% of model weights). In case of BERT and other pre-trained encoder Transformers, the affected component is the scaling factors and biases in the LayerNorm. The outliers are high-magnitude normalization parameters that emerge early in pre-training and show up consistently in the same dimensional position throughout the model. We show that disabling them significantly degrades both the MLM loss and the downstream task performance. This effect is observed across several BERT-family models and other popular pre-trained Transformer architectures, including BART, XLNet and ELECTRA; we also show a similar effect in GPT-2.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="Rogers_2021_Changing_World_by_Changing_Data"><b>Rogers, A.</b> (2021). Changing the World by Changing the Data. <i>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</i>, 2182–2194. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('Rogers_2021_Changing_World_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.acl-long.170'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.acl-long.170.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id="Rogers_2021_Changing_World_abs">NLP community is currently investing a lot more research and resources into development of deep learning models than training data. While we have made a lot of progress, it is now clear that our models learn all kinds of spurious patterns, social biases, and annotation artifacts. Algorithmic solutions have so far had limited success. An alternative that is being actively discussed is more careful design of datasets so as to deliver specific signals. This position paper maps out the arguments for and against data curation, and argues that fundamentally the point is moot: curation already is and will be happening, and it is changing the world. The question is only how much thought we want to invest into that process.</div>
    
</div>



    
</li>
</ol>

<h2 id="2020">2020</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    

    

    

    
    <img class="emoji" title=":ledger:" alt=":ledger:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d2.png" height="20" width="20">
    

    

    <span id="RogersKovalevaEtAl_2020_Primer_in_BERTology_What_We_Know_About_How_BERT_Works"><b>Rogers, A.</b>, Kovaleva, O., &amp; Rumshisky, A. (2020). A Primer in BERTology: What We Know About How BERT Works. <i>Transactions of the Association for Computational Linguistics</i>, <i>8</i>, 842–866.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersKovalevaEtAl_2020_Primer_in_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://doi.org/10.1162/tacl_a_00349'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2020.tacl-1.54.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id="RogersKovalevaEtAl_2020_Primer_in_abs">Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="insights-2020-insights"><b>Rogers, A.</b>, Sedoc, J., &amp; Rumshisky, A. (Eds.). (2020). <i>Proceedings of the First Workshop on Insights from Negative Results in NLP</i>. Online: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2020.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="RogersAugenstein_2020_What_Can_We_Do_to_Improve_Peer_Review_in_NLP"><b>Rogers, A.</b>, &amp; Augenstein, I. (2020). What Can We Do to Improve Peer Review in NLP? <i>Findings of EMNLP</i>, 1256–1262. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersAugenstein_2020_What_Can_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/2020.findings-emnlp.112/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="RogersAugenstein_2020_What_Can_abs">Peer review is our best tool for judging the quality of conference submissions, but it is becoming increasingly spurious. We argue that a part of the problem is that the reviewers and area chairs face a poorly defined task forcing apples-to-oranges comparisons. There are several potential ways forward, but the key difficulty is creating the incentives and mechanisms for their consistent implementation in the NLP community.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="PrasannaRogersEtAl_2020_When_BERT_Plays_Lottery_All_Tickets_Are_Winning">Prasanna, S., <b>Rogers, A.</b>, &amp; Rumshisky, A. (2020). When BERT Plays the Lottery, All Tickets Are Winning. <i>Proceedings of EMNLP</i>, 3208–3229. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('PrasannaRogersEtAl_2020_When_BERT_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/2020.emnlp-main.259/'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://slideslive.com/38939762/when-bert-plays-the-lottery-all-tickets-are-winning'">VIDEO</button>
    

    

    

    
    <div class="abstract" id="PrasannaRogersEtAl_2020_When_BERT_abs">Much of the recent success in NLP is due to the large Transformer-based models such as BERT (Devlin et al, 2019). However, these models have been shown to be reducible to a smaller number of self-attention heads and layers. We consider this phenomenon from the perspective of the lottery ticket hypothesis. For fine-tuned BERT, we show that (a) it is possible to find a subnetwork of elements that achieves performance comparable with that of the full model, and (b) similarly-sized subnetworks sampled from the rest of the model perform worse. However, the "bad" subnetworks can be fine-tuned separately to achieve only slightly worse performance than the "good" ones, indicating that most weights in the pre-trained BERT are potentially useful. We also show that the "good" subnetworks vary considerably across GLUE tasks, opening up the possibilities to learn what knowledge BERT actually uses at inference time.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="RogersKovalevaEtAl_2020_Getting_Closer_to_AI_Complete_Question_Answering_Set_of_Prerequisite_Real_Tasks"><b>Rogers, A.</b>, Kovaleva, O., Downey, M., &amp; Rumshisky, A. (2020). Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks. <i>Proceedings of the  AAAI Conference on Artificial Intelligence</i>, 11.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersKovalevaEtAl_2020_Getting_Closer_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aaai.org/ojs/index.php/AAAI/article/view/6398'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://text-machine-lab.github.io/blog/2020/quail/'">BLOG</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://text-machine.cs.uml.edu/lab2/projects/quail/'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id="RogersKovalevaEtAl_2020_Getting_Closer_abs">The recent explosion in question answering research produced a wealth of both factoid RC and commonsense reasoning datasets. Combining them presents a different kind of task: not deciding simply whether information is present in the text, but also whether a confident guess could be made for the missing information. To that end, we present QuAIL, the first reading comprehension dataset (a) to combine textbased, world knowledge and unanswerable questions, and (b) to provide annotation that would enable precise diagnostics of the reasoning strategies by a given QA system. QuAIL contains 15K multi-choice questions for 800 texts in 4 domains (fiction, blogs, political news, and user story texts). Crucially, to solve QuAIL a system would need to handle both general and text-specific questions, impossible to answer from pretraining data. We show that the new benchmark poses substantial challenges to the current state-of-the-art systems, with a 30% drop in accuracy compared to the most similar existing dataset.</div>
    
</div>



    
</li>
</ol>

<h2 id="2019">2019</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="RomanovRumshiskyEtAl_2019_Adversarial_Decomposition_of_Text_Representation">Romanov, A., Rumshisky, A., <b>Rogers, A.</b>, &amp; Donahue, D. (2019). Adversarial Decomposition of Text Representation. <i>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</i>, 815–825.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RomanovRumshiskyEtAl_2019_Adversarial_Decomposition_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclweb.org/anthology/papers/N/N19/N19-1088/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="RomanovRumshiskyEtAl_2019_Adversarial_Decomposition_abs">In this paper, we present a method for adversarial decomposition of text representation. This method can be used to decompose a representation of an input sentence into several independent vectors, each of them responsible for a specific aspect of the input sentence. We evaluate the proposed method on two case studies: the conversion between different social registers and diachronic language change. We show that the proposed method is capable of fine-grained controlled change of these aspects of the input sentence. It is also learning a continuous (rather than categorical) representation of the style of the sentence, which is more linguistically realistic. The model uses adversarial-motivational training and includes a special motivational loss, which acts opposite to the discriminator and encourages a better decomposition. Furthermore, we evaluate the obtained meaning embeddings on a downstream task of paraphrase detection and show that they significantly outperform the embeddings of a regular autoencoder.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="KovalevaRomanovEtAl_2019_Revealing_Dark_Secrets_of_BERT">Kovaleva, O., Romanov, A., <b>Rogers, A.</b>, &amp; Rumshisky, A. (2019). Revealing the Dark Secrets of BERT. <i>Proceedings of EMNLP-IJCNLP)</i>, 4356–4365. https://doi.org/10.18653/v1/D19-1445</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KovalevaRomanovEtAl_2019_Revealing_Dark_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/D19-1445'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://text-machine-lab.github.io/blog/2020/bert-secrets/'">BLOG</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/text-machine-lab/dark-secrets-of-BERT/'">CODE</button>
    

    

    

    

    

    

    

    
    <div class="abstract" id="KovalevaRomanovEtAl_2019_Revealing_Dark_abs">BERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT’s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    
    <img class="emoji" title=":notebook:" alt=":notebook:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d3.png" height="20" width="20">
    

    

    

    

    

    

    <span id="RogersDrozdEtAl_2019_Proceedings_of_3rd_Workshop_on_Evaluating_Vector_Space_Representations_for_NLP"><b>Rogers, A.</b>, Drozd, A., Rumshisky, A., &amp; Goldberg, Y. (2019). <i>Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP</i>.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/papers/W/W19/W19-2000/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="RogersKovalevaEtAl_2019_Calls_to_Action_on_Social_Media_Potential_for_Censorship_and_Social_Impact"><b>Rogers, A.</b>, Kovaleva, O., &amp; Rumshisky, A. (2019). Calls to Action on Social Media: Potential for Censorship and Social Impact. <i>EMNLP-IJCNLP 2019 Second Workshop on Natural Language Processing for Internet Freedom</i>.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersKovalevaEtAl_2019_Calls_to_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/D19-5005'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="RogersKovalevaEtAl_2019_Calls_to_abs">Calls to action on social media are known to be effective means of mobilization in social movements, and a frequent target of censorship. We investigate the possibility of their automatic detection and their potential for predicting real-world protest events, on historical data of Bolotnaya protests in Russia (2011-2013). We find that political calls to action can be annotated and detected with relatively high accuracy, and that in our sample their volume has a moderate positive correlation with rally attendance.</div>
    
</div>



    
</li>
</ol>

<h2 id="2018">2018</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="KarpinskaLiEtAl_2018_Subcharacter_Information_in_Japanese_Embeddings_When_Is_It_Worth_It">Karpinska, M., Li, B., <b>Rogers, A.</b>, &amp; Drozd, A. (2018). Subcharacter Information in Japanese Embeddings: When Is It Worth It? <i>Proceedings of the Workshop on the Relevance of Linguistic Structure in Neural Architectures for NLP</i>, 28–37. Melbourne, Australia: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KarpinskaLiEtAl_2018_Subcharacter_Information_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/W18-2905'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/jBATS/'">BLOG</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/jBATS/'">CODE</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/jBATS/'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id="KarpinskaLiEtAl_2018_Subcharacter_Information_abs">Languages with logographic writing systems present a difficulty for traditional character-level models. Leveraging the subcharacter information was recently shown to be beneficial for a number of intrinsic and extrinsic tasks in Chinese. We examine whether the same strategies could be applied for Japanese, and contribute a new analogy dataset for this language.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="RogersHosurAnanthakrishnaEtAl_2018_Whats_in_Your_Embedding_And_How_It_Predicts_Task_Performance"><b>Rogers, A.</b>, Hosur Ananthakrishna, S., &amp; Rumshisky, A. (2018). What’s in Your Embedding, And How It Predicts Task Performance. <i>Proceedings of the 27th International Conference on Computational Linguistics</i>, 2690–2703. Santa Fe, New Mexico, USA, August 20-26, 2018: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersHosurAnanthakrishnaEtAl_2018_Whats_in_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/C18-1228'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://ldtoolkit.space'">CODE</button>
    

    

    

    

    

    

    

    
    <div class="abstract" id="RogersHosurAnanthakrishnaEtAl_2018_Whats_in_abs">Attempts to find a single technique for general-purpose intrinsic evaluation of word embeddings have so far not been successful. We present a new approach based on scaled-up qualitative analysis of word vector neighborhoods that quantifies interpretable characteristics of a given model (e.g. its preference for synonyms or shared morphological forms as nearest neighbors). We analyze 21 such factors and show how they correlate with performance on 14 extrinsic and intrinsic task datasets (and also explain the lack of correlation between some of them). Our approach enables multi-faceted evaluation, parameter search, and generally – a more principled, hypothesis-driven approach to development of distributional semantic representations.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="RogersRomanovEtAl_2018_RuSentiment_Enriched_Sentiment_Analysis_Dataset_for_Social_Media_in_Russian"><b>Rogers, A.</b>, Romanov, A., Rumshisky, A., Volkova, S., Gronas, M., &amp; Gribov, A. (2018). RuSentiment: An Enriched Sentiment Analysis Dataset for Social Media in Russian. <i>Proceedings of the 27th International Conference on Computational Linguistics</i>, 755–763. Santa Fe, New Mexico, USA: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersRomanovEtAl_2018_RuSentiment_Enriched_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/C18-1064'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/text-machine-lab/rusentiment_baselines'">CODE</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://text-machine.cs.uml.edu/lab2/projects/rusentiment/'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id="RogersRomanovEtAl_2018_RuSentiment_Enriched_abs">This paper presents RuSentiment, a new dataset for sentiment analysis of social media posts in Russian, and a new set of comprehensive annotation guidelines that are extensible to other languages. RuSentiment is currently the largest in its class for Russian, with 31,185 posts annotated with Fleiss’ kappa of 0.58 (3 annotations per post). To diversify the dataset, 6,950 posts were pre-selected with an active learning-style strategy. We report baseline classification results, and we also release the best-performing embeddings trained on 3.2B tokens of Russian VKontakte posts.</div>
    
</div>



    
</li>
</ol>

<h2 id="2017">2017</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="LiLiuEtAl_2017_Investigating_different_syntactic_context_types_and_context_representations_for_learning_word_embeddings">Li, B., Liu, T., Zhao, Z., Tang, B., Drozd, A., <b>Rogers, A.</b>, &amp; Du, X. (2017). Investigating Different Syntactic Context Types and Context Representations for Learning Word Embeddings. <i>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</i>, 2411–2421. Copenhagen, Denmark, September 7–11, 2017.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('LiLiuEtAl_2017_Investigating_different_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/D17-1257'">PDF</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.readthedocs.io/en/docs/tutorial/getting_vectors.html#pre-trained-vsms'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id="LiLiuEtAl_2017_Investigating_different_abs">The number of word embedding models is growing every year. Most of them are based on the co-occurrence information of words and their contexts. However, it is still an open question what is the best definition of context. We provide a systematical investigation of 4 different syntactic context types and context representations for learning word embeddings. Comprehensive experiments are conducted to evaluate their effectiveness on 6 extrinsic and intrinsic tasks. We hope that this paper, along with the published code, would be helpful for choosing the best context type and representation for a given task.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    

    

    

    

    <span id="Rogers_2017_Multilingual_computational_lexicography_frame_semantics_meets_distributional_semantics"><b>Rogers, A.</b> (2017). <i>Multilingual Computational Lexicography: Frame Semantics Meets Distributional Semantics</i> (Ph.D. Dissertation, University of Tokyo). University of Tokyo, Tokyo.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://repository.dl.itc.u-tokyo.ac.jp/records/52196'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="RogersDrozdEtAl_2017_Too_Many_Problems_of_Analogical_Reasoning_with_Word_Vectors"><b>Rogers, A.</b>, Drozd, A., &amp; Li, B. (2017). The (Too Many) Problems of Analogical Reasoning with Word Vectors. <i>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (* SEM 2017)</i>, 135–148.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersDrozdEtAl_2017_Too_Many_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.aclweb.org/anthology/S17-1017'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="RogersDrozdEtAl_2017_Too_Many_abs">This paper explores the possibilities of analogical reasoning with vector space models. Given two pairs of words with the same relation (e.g. man:woman :: king:queen), it was proposed that the offset between one pair of the corresponding word vectors can be used to identify the unknown member of the other pair (king - man + woman = queen). We argue against such “linguistic regularities” as a model for linguistic relations in vector space models and as a benchmark, and we show that the vector offset (as well as two other, better-performing methods) suffers from dependence on vector similarity.</div>
    
</div>



    
</li>
</ol>

<h2 id="2016">2016</h2>

<p><em>(before 2017 my last name was “Gladkova”)</em></p>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20"> <img class="emoji" title=":large_orange_diamond:" alt=":large_orange_diamond:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f536.png" height="20" width="20">
    

    

    

    

    <span id="DrozdGladkovaEtAl_2016_Word_embeddings_analogies_and_machine_learning_beyond_king_-_man_woman_queen">Drozd, A., <b>Gladkova, A.</b>, &amp; Matsuoka, S. (2016). Word Embeddings, Analogies, and Machine Learning: Beyond King - Man + Woman = Queen. <i>Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</i>, 3519–3530. Osaka, Japan, December 11-17.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/C/C16/C16-1332.pdf'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/vecto-ai/vecto/'">CODE</button>
    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="GladkovaDrozd_2016_Intrinsic_evaluations_of_word_embeddngs_what_can_we_do_better"><b>Gladkova, A.</b>, &amp; Drozd, A. (2016). Intrinsic Evaluations of Word Embeddings: What Can We Do Better? <i>Proceedings of The 1st Workshop on Evaluating Vector Space Representations for NLP</i>, 36–42. https://doi.org/10.18653/v1/W16-2507</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.aclweb.org/anthology/W/W16/W16-2507.pdf'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="GladkovaDrozdEtAl_2016_Analogy-based_detection_of_morphological_and_semantic_relations_with_word_embeddings_what_works_and_what_doesnt"><b>Gladkova, A.</b>, Drozd, A., &amp; Matsuoka, S. (2016). Analogy-Based Detection of Morphological and Semantic Relations with Word Embeddings: What Works and What Doesn’t. <i>Proceedings of the NAACL-HLT SRW</i>, 47–54. https://doi.org/10.18653/v1/N16-2002</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/N/N16/N16-2002.pdf'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/BATS/'">BLOG</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/BATS/'">CODE</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/BATS/'">DATA</button>
    

    

    

    

    

    

    
</div>



    
</li>
<li>
<div class="text-justify">

    

    

    

    
    <img class="emoji" title=":black_nib:" alt=":black_nib:" src="https://github.githubassets.com/images/icons/emoji/unicode/2712.png" height="20" width="20">
    

    

    

    <span id="SantusGladkovaEtAl_2016_CogALex-V_shared_task_on_corpus-based_identification_of_semantic_relations">Santus, E., <b>Gladkova, A.</b>, Evert, S., &amp; Lenci, A. (2016). The CogALex-V Shared Task on the Corpus-Based Identification of Semantic Relations. Osaka, Japan, December 11-17: ACL.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.aclweb.org/anthology/W/W16/W16-53.pdf#page=83'">PDF</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://sites.google.com/site/cogalex2016/home/shared-task'">DATA</button>
    

    

    

    

    

    

    
</div>



    
</li>
</ol>

<h2 id="2015">2015</h2>

<ol class="bibliography">
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="DrozdGladkovaEtAl_2015_Discovering_aspectual_classes_of_Russian_verbs_in_untagged_large_corpora">Drozd, A., <b>Gladkova, A.</b>, &amp; Matsuoka, S. (2015). Discovering Aspectual Classes of Russian Verbs in Untagged Large Corpora. <i>Proceedings of 2015 IEEE International Conference on Data Science and Data Intensive Systems (DSDIS)</i>, 61–68. https://doi.org/10.1109/DSDIS.2015.30</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('DrozdGladkovaEtAl_2015_Discovering_aspectual_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.ieeexplore.ieee.org/document/7396482/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="DrozdGladkovaEtAl_2015_Discovering_aspectual_abs">This paper presents a case study of discovering and classifying verbs in large web-corpora. Many tasks in natural language processing require corpora containing billions of words, and with such volumes of data co-occurrence extraction becomes one of the performance bottlenecks in the Vector Space Models of computational linguistics. We propose a co-occurrence extraction kernel based on ternary trees as an alternative (or a complimentary stage) to conventional map-reduce based approach, this kernel achieves an order of magnitude improvement in memory footprint and processing speed. Our classifier successfully and efficiently identified verbs in a 1.2-billion words untagged corpus of Russian fiction and distinguished between their two aspectual classes. The model proved efficient even for low-frequency vocabulary, including nonce verbs and neologisms.</div>
    
</div>



    
</li>
<li>
<div class="text-justify">

    

    
    <img class="emoji" title=":newspaper:" alt=":newspaper:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4f0.png" height="20" width="20">
    

    

    

    

    

    <span id="DrozdGladkovaEtAl_2015_Python_performance_and_Natural_Language_Processing">Drozd, A., <b>Gladkova, A.</b>, &amp; Matsuoka, S. (2015). Python, Performance, and Natural Language Processing. <i>Proceedings of the 5th Workshop on Python for High-Performance and Scientific Computing</i>, 1:1–1:10. https://doi.org/10.1145/2835857.2835858</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('DrozdGladkovaEtAl_2015_Python_performance_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://dl.acm.org/citation.cfm?id=2835858'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id="DrozdGladkovaEtAl_2015_Python_performance_abs">We present a case study of Python-based workflow for a data-intensive natural language processing problem, namely word classification with vector space model methodology. Problems in the area of natural language processing are typically solved in many steps which require transformation of the data to vastly different formats (in our case, raw text to sparse matrices to dense vectors). A Python implementation for each of these steps would require a different solution. We survey existing approaches to using Python for high-performance processing of large volumes of data, and we propose a sample solution for each step for our case study (aspectual classification of Russian verbs), attempting to preserve both efficiency and user-friendliness. For the most computationally intensive part of the workflow we develop a prototype distributed implementation of co-occurrence extraction module using IPython.parallel cluster.</div>
    
</div>



    
</li>
</ol>

<!--

# Publications sorted by type

## Journal articles

<ol class="bibliography"><li><div class="text-justify">

    

    

    

    

    
    :ledger:
    

    

    <span id="SavcisensEliassi-RadEtAl_2024_Using_sequences_of_life-events_to_predict_human_lives">Savcisens, G., Eliassi-Rad, T., Hansen, L. K., Mortensen, L. H., Lilleholt, L., <b>Rogers, A.</b>, … Lehmann, S. (2024). Using Sequences of Life-Events to Predict Human Lives. <i>Nature Computational Science</i>, <i>4</i>(1), 43–56.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('SavcisensEliassi-RadEtAl_2024_Using_sequences_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'Here we represent human lives in a way that shares structural similarity to language, and we exploit this similarity to adapt natural language processing techniques to examine the evolution and predictability of human lives based on detailed event sequences. We do this by drawing on a comprehensive registry dataset, which is available for Denmark across several years, and that includes information about life-events related to health, education, occupation, income, address and working hours, recorded with day-to-day resolution. We create embeddings of life-events in a single vector space, showing that this embedding space is robust and highly structured. Our models allow us to predict diverse outcomes ranging from early mortality to personality nuances, outperforming state-of-the-art models by a wide margin. Using methods for interpreting deep learning models, we probe the algorithm to understand the factors that enable our predictions. Our framework allows researchers to discover potential mechanisms that impact life outcomes as well as the associated possibilities for personalized interventions.'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='SavcisensEliassi-RadEtAl_2024_Using_sequences_abs'>https://arxiv.org/pdf/2306.03009.pdf</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    

    

    
    :ledger:
    

    

    <span id="RogersGardnerEtAl_2021_QA_Dataset_Explosion_Taxonomy_of_NLP_Resources_for_Question_Answering_and_Reading_Comprehension"><b>Rogers, A.</b>, Gardner, M., &amp; Augenstein, I. (2022). QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension. <i>ACM CSUR</i>. https://doi.org/https://doi.org/10.1145/3560260</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersGardnerEtAl_2021_QA_Dataset_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://arxiv.org/abs/2107.12708'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='RogersGardnerEtAl_2021_QA_Dataset_abs'>Alongside huge volumes of research on deep learning models in NLP in the recent years, there has been also much work on benchmark datasets needed to track modeling progress. Question answering and reading comprehension have been particularly prolific in this regard, with over 80 new datasets appearing in the past two years. This study is the largest survey of the field to date. We provide an overview of the various formats and domains of the current resources, highlighting the current lacunae for future work. We further discuss the current classifications of “reasoning types" in question answering and propose a new taxonomy. We also discuss the implications of over-focusing on English, and survey the current monolingual resources for other languages and multilingual resources. The study is aimed at both practitioners looking for pointers to the wealth of existing data, and at researchers working on new resources.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    

    

    
    :ledger:
    

    

    <span id="RogersKovalevaEtAl_2020_Primer_in_BERTology_What_We_Know_About_How_BERT_Works"><b>Rogers, A.</b>, Kovaleva, O., &amp; Rumshisky, A. (2020). A Primer in BERTology: What We Know About How BERT Works. <i>Transactions of the Association for Computational Linguistics</i>, <i>8</i>, 842–866.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersKovalevaEtAl_2020_Primer_in_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://doi.org/10.1162/tacl_a_00349'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2020.tacl-1.54.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id='RogersKovalevaEtAl_2020_Primer_in_abs'>Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.</div>
    
</div>



    
</li></ol>

## Top-tier conference articles

<ol class="bibliography"><li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="puccetti2024ainewscontentfarms">Puccetti, G., <b>Rogers, A.</b>, Alzetta, C., Dell’Orletta, F., &amp; Esuli, A. (2024). AI ‘News’ Content Farms Are Easy to Make and Hard to Detect: A Case Study in Italian. In L.-W. Ku, A. Martins, &amp; V. Srikumar (Eds.), <i>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i> (pp. 15312–15338). Bangkok, Thailand: Association for Computational Linguistics.</span>

    
    

    
    :trophy: <b>Area Chair Award</b>
    

    
    <button class="btn--info" onclick="showBibtex('puccetti2024ainewscontentfarms_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2024.acl-long.817'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='puccetti2024ainewscontentfarms_abs'>Large Language Models (LLMs) are increasingly used as ‘content farm’ models (CFMs), to generate synthetic text that could pass for real news articles. This is already happening even for languages that do not have high-quality monolingual LLMs. We show that fine-tuning Llama (v1), mostly trained on English, on as little as 40K Italian news articles, is sufficient for producing news-like texts that native speakers of Italian struggle to identify as synthetic.We investigate three LLMs and three methods of detecting synthetic texts (log-likelihood, DetectGPT, and supervised classification), finding that they all perform better than human raters, but they are all impractical in the real world (requiring either access to token likelihood information or a large dataset of CFM texts). We also explore the possibility of creating a proxy CFM: an LLM fine-tuned on a similar dataset to one used by the real ‘content farm’. We find that even a small amount of fine-tuning data suffices for creating a successful detector, but we need to know which base LLM is used, which is a major challenge.Our results suggest that there are currently no practical methods for detecting synthetic news-like texts ‘in the wild’, while generating them is too easy. We highlight the urgency of more NLP research on this problem.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="rogers2024position"><b>Rogers, A.</b>, &amp; Luccioni, S. (2024). Position: Key Claims in LLM Research Have a Long Tail of Footnotes. <i>Forty-first International Conference on Machine Learning</i>.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('rogers2024position_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://openreview.net/forum?id=M2cwkGleRL'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='rogers2024position_abs'>Much of the recent discourse within the ML community has been centered around Large Language Models (LLMs), their functionality and potential – yet not only do we not have a working definition of LLMs, but much of this discourse relies on claims and assumptions that are worth re-examining. We contribute a definition of LLMs, critically examine five common claims regarding their properties (including ’emergent properties’), and conclude with suggestions for future research directions and their framing.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="rogers-etal-2024-narrativetime-dense"><b>Rogers, A.</b>, Karpinska, M., Gupta, A., Lialin, V., Smelkov, G., &amp; Rumshisky, A. (2024). NarrativeTime: Dense Temporal Annotation on a Timeline. In N. Calzolari, M.-Y. Kan, V. Hoste, A. Lenci, S. Sakti, &amp; N. Xue (Eds.), <i>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</i> (pp. 12053–12073). Torino, Italia: ELRA and ICCL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('rogers-etal-2024-narrativetime-dense_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2024.lrec-main.1054'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='rogers-etal-2024-narrativetime-dense_abs'>For the past decade, temporal annotation has been sparse: only a small portion of event pairs in a text was annotated. We present NarrativeTime, the first timeline-based annotation framework that achieves full coverage of all possible TLINKs. To compare with the previous SOTA in dense temporal annotation, we perform full re-annotation of the classic TimeBankDense corpus (American English), which shows comparable agreement with a signigicant increase in density. We contribute TimeBankNT corpus (with each text fully annotated by two expert annotators), extensive annotation guidelines, open-source tools for annotation and conversion to TimeML format, and baseline results.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="jimenezsanchez2024copycats">Jiménez-Sánchez, A., Avlona, N.-R., Juodelyte, D., Sourget, T., Vang-Larsen, C., <b>Rogers, A.</b>, … Cheplygina, V. (2024). Copycats: the many lives of a publicly available medical imaging dataset. <i>The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track</i>.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('jimenezsanchez2024copycats_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://openreview.net/forum?id=X4KImMSIRq'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='jimenezsanchez2024copycats_abs'>Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data’s public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets’ context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="PiktusAkikiEtAl_2023_ROOTS_Search_Tool_Data_Transparency_for_LLMs">Piktus, A., Akiki, C., Villegas, P., Laurençon, H., Dupont, G., Luccioni, S., … <b>Rogers, A.</b> (2023). The ROOTS Search Tool: Data Transparency for LLMs. <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)</i>, 304–314. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('PiktusAkikiEtAl_2023_ROOTS_Search_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-demo.29'">PDF</button>
    

    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://huggingface.co/spaces/bigscience-data/roots-search'">DEMO</button>
    

    

    
    <div class="abstract" id='PiktusAkikiEtAl_2023_ROOTS_Search_abs'>ROOTS is a 1.6TB multilingual text corpus developed for the training of BLOOM, currently the largest language model explicitly accompanied by commensurate data governance efforts. In continuation of these efforts, we present the ROOTS Search Tool: a search engine over the entire ROOTS corpus offering both fuzzy and exact search capabilities. ROOTS is the largest corpus to date that can be investigated this way. The ROOTS Search Tool is open-sourced and available on Hugging Face Spaces: https://huggingface.co/spaces/bigscience-data/roots-search. We describe our implementation and the possible use cases of our tool.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="LaurenconSaulnierEtAl_2022_BigScience_ROOTS_Corpus_6TB_Composite_Multilingual_Dataset">Laurençon, H., Saulnier, L., Wang, T., Akiki, C., Villanova del Moral, A., Le Scao, T., … Jernite, Y. (2022). The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset. <i>Thirty-Sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track</i>. Presented at the New Orleans, United States. New Orleans, United States.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('LaurenconSaulnierEtAl_2022_BigScience_ROOTS_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://openreview.net/forum?id=UoEw6KigkUn'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='LaurenconSaulnierEtAl_2022_BigScience_ROOTS_abs'>As language models grow ever larger, the need for large-scale high-quality text datasets has never been more pressing, especially in multilingual settings. The BigScience workshop, a 1-year international and multidisciplinary initiative, was formed with the goal of researching and training large language models as a values-driven undertaking, putting issues of ethics, harm, and governance in the foreground. This paper documents the data creation and curation efforts undertaken by BigScience to assemble the Responsible Open-science Open-collaboration Text Sources (ROOTS) corpus, a 1.6TB dataset spanning 59 languages that was used to train the 176-billion-parameter BigScience Large Open-science Open-access Multilingual (BLOOM) language model. We further release a large initial subset of the corpus and analyses thereof, and hope to empower large-scale monolingual and multilingual modeling projects with both the data and the processing tools, as well as stimulate research around this large multilingual corpus.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="thorn-jakobsen-rogers-2022-factors">Thorn Jakobsen, T., &amp; <b>Rogers, A.</b> (2022). What Factors Should Paper-Reviewer Assignments Rely On? Community Perspectives on Issues and Ideals in Conference Peer-Review. <i>Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</i>, 4810–4823. Seattle, United States: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('thorn-jakobsen-rogers-2022-factors_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.naacl-main.354'">PDF</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/terne/Paper-Reviewer-Matching-Surveys'">DATA</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.naacl-main.354.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id='thorn-jakobsen-rogers-2022-factors_abs'>Both scientific progress and individual researcher careers depend on the quality of peer review, which in turn depends on paper-reviewer matching. Surprisingly, this problem has been mostly approached as an automated recommendation problem rather than as a matter where different stakeholders (area chairs, reviewers, authors) have accumulated experience worth taking into account. We present the results of the first survey of the NLP community, identifying common issues and perspectives on what factors should be considered by paper-reviewer matching systems. This study contributes actionable recommendations for improving future NLP conferences, and desiderata for interpretable peer review assignments.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="JerniteNguyenEtAl_2022_Data_Governance_in_Age_of_Large-Scale_Data-Driven_Language_Technology">Jernite, Y., Nguyen, H., Biderman, S., <b>Rogers, A.</b>, Masoud, M., Danchev, V., … Mitchell, M. (2022). Data Governance in the Age of Large-Scale Data-Driven Language Technology. <i>2022 ACM Conference on Fairness, Accountability, and Transparency</i>, 2206–2222. https://doi.org/10.1145/3531146.3534637</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('JerniteNguyenEtAl_2022_Data_Governance_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://dl.acm.org/doi/10.1145/3531146.3534637'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='JerniteNguyenEtAl_2022_Data_Governance_abs'>The recent emergence and adoption of Machine Learning technology, and specifically of Large Language Models, has drawn attention to the need for systematic and transparent management of language data. This work proposes an approach to global language data governance that attempts to organize data management amongst stakeholders, values, and rights. Our proposal is informed by prior work on distributed governance that accounts for human values and grounded by an international research collaboration that brings together researchers and practitioners from 60 countries. The framework we present is a multi-party international governance structure focused on language data, and incorporating technical and organizational tools needed to support its work.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="ray-choudhury-etal-2022-machine">Ray Choudhury, S., <b>Rogers, A.</b>, &amp; Augenstein, I. (2022). Machine Reading, Fast and Slow: When Do Models ’Understand’ Language? <i>Proceedings of the 29th International Conference on Computational Linguistics</i>, 78–93. Gyeongju, Republic of Korea.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('ray-choudhury-etal-2022-machine_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.coling-1.8'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='ray-choudhury-etal-2022-machine_abs'>Two of the most fundamental issues in Natural Language Understanding (NLU) at present are: (a) how it can established whether deep
    learning-based models score highly on NLU benchmarks for the ’right’ reasons; and (b) what those reasons would even be.
    We investigate the behavior of reading comprehension models with respect to two linguistic ’skills’:
    coreference resolution and comparison. We propose a definition for the reasoning steps expected from a system that would be ’reading slowly’,
    and compare that with the behavior of five models of the BERT family of various sizes, observed through saliency scores and counterfactual explanations.
    We find that for comparison (but not coreference) the systems based on larger encoders are more likely to rely on the ’right’ information, but even
    they struggle with generalization, suggesting that they still learn specific lexical patterns rather than the general principles of comparison.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="Rogers_2021_Changing_World_by_Changing_Data"><b>Rogers, A.</b> (2021). Changing the World by Changing the Data. <i>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</i>, 2182–2194. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('Rogers_2021_Changing_World_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.acl-long.170'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.acl-long.170.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id='Rogers_2021_Changing_World_abs'>NLP community is currently investing a lot more research and resources into development of deep learning models than training data. While we have made a lot of progress, it is now clear that our models learn all kinds of spurious patterns, social biases, and annotation artifacts. Algorithmic solutions have so far had limited success. An alternative that is being actively discussed is more careful design of datasets so as to deliver specific signals. This position paper maps out the arguments for and against data curation, and argues that fundamentally the point is moot: curation already is and will be happening, and it is changing the world. The question is only how much thought we want to invest into that process.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="PrasannaRogersEtAl_2020_When_BERT_Plays_Lottery_All_Tickets_Are_Winning">Prasanna, S., <b>Rogers, A.</b>, &amp; Rumshisky, A. (2020). When BERT Plays the Lottery, All Tickets Are Winning. <i>Proceedings of EMNLP</i>, 3208–3229. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('PrasannaRogersEtAl_2020_When_BERT_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/2020.emnlp-main.259/'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://slideslive.com/38939762/when-bert-plays-the-lottery-all-tickets-are-winning'">VIDEO</button>
    

    

    

    
    <div class="abstract" id='PrasannaRogersEtAl_2020_When_BERT_abs'>Much of the recent success in NLP is due to the large Transformer-based models such as BERT (Devlin et al, 2019). However, these models have been shown to be reducible to a smaller number of self-attention heads and layers. We consider this phenomenon from the perspective of the lottery ticket hypothesis. For fine-tuned BERT, we show that (a) it is possible to find a subnetwork of elements that achieves performance comparable with that of the full model, and (b) similarly-sized subnetworks sampled from the rest of the model perform worse. However, the "bad" subnetworks can be fine-tuned separately to achieve only slightly worse performance than the "good" ones, indicating that most weights in the pre-trained BERT are potentially useful. We also show that the "good" subnetworks vary considerably across GLUE tasks, opening up the possibilities to learn what knowledge BERT actually uses at inference time.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="RogersKovalevaEtAl_2020_Getting_Closer_to_AI_Complete_Question_Answering_Set_of_Prerequisite_Real_Tasks"><b>Rogers, A.</b>, Kovaleva, O., Downey, M., &amp; Rumshisky, A. (2020). Getting Closer to AI Complete Question Answering: A Set of Prerequisite Real Tasks. <i>Proceedings of the  AAAI Conference on Artificial Intelligence</i>, 11.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersKovalevaEtAl_2020_Getting_Closer_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aaai.org/ojs/index.php/AAAI/article/view/6398'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://text-machine-lab.github.io/blog/2020/quail/'">BLOG</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://text-machine.cs.uml.edu/lab2/projects/quail/'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id='RogersKovalevaEtAl_2020_Getting_Closer_abs'>The recent explosion in question answering research produced a wealth of both factoid RC and commonsense reasoning datasets. Combining them presents a different kind of task: not deciding simply whether information is present in the text, but also whether a confident guess could be made for the missing information. To that end, we present QuAIL, the first reading comprehension dataset (a) to combine textbased, world knowledge and unanswerable questions, and (b) to provide annotation that would enable precise diagnostics of the reasoning strategies by a given QA system. QuAIL contains 15K multi-choice questions for 800 texts in 4 domains (fiction, blogs, political news, and user story texts). Crucially, to solve QuAIL a system would need to handle both general and text-specific questions, impossible to answer from pretraining data. We show that the new benchmark poses substantial challenges to the current state-of-the-art systems, with a 30% drop in accuracy compared to the most similar existing dataset.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="RomanovRumshiskyEtAl_2019_Adversarial_Decomposition_of_Text_Representation">Romanov, A., Rumshisky, A., <b>Rogers, A.</b>, &amp; Donahue, D. (2019). Adversarial Decomposition of Text Representation. <i>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</i>, 815–825.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RomanovRumshiskyEtAl_2019_Adversarial_Decomposition_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclweb.org/anthology/papers/N/N19/N19-1088/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='RomanovRumshiskyEtAl_2019_Adversarial_Decomposition_abs'>In this paper, we present a method for adversarial decomposition of text representation. This method can be used to decompose a representation of an input sentence into several independent vectors, each of them responsible for a specific aspect of the input sentence. We evaluate the proposed method on two case studies: the conversion between different social registers and diachronic language change. We show that the proposed method is capable of fine-grained controlled change of these aspects of the input sentence. It is also learning a continuous (rather than categorical) representation of the style of the sentence, which is more linguistically realistic. The model uses adversarial-motivational training and includes a special motivational loss, which acts opposite to the discriminator and encourages a better decomposition. Furthermore, we evaluate the obtained meaning embeddings on a downstream task of paraphrase detection and show that they significantly outperform the embeddings of a regular autoencoder.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="KovalevaRomanovEtAl_2019_Revealing_Dark_Secrets_of_BERT">Kovaleva, O., Romanov, A., <b>Rogers, A.</b>, &amp; Rumshisky, A. (2019). Revealing the Dark Secrets of BERT. <i>Proceedings of EMNLP-IJCNLP)</i>, 4356–4365. https://doi.org/10.18653/v1/D19-1445</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KovalevaRomanovEtAl_2019_Revealing_Dark_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/D19-1445'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://text-machine-lab.github.io/blog/2020/bert-secrets/'">BLOG</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/text-machine-lab/dark-secrets-of-BERT/'">CODE</button>
    

    

    

    

    

    

    

    
    <div class="abstract" id='KovalevaRomanovEtAl_2019_Revealing_Dark_abs'>BERT-based architectures currently give state-of-the-art performance on many NLP tasks, but little is known about the exact mechanisms that contribute to its success. In the current work, we focus on the interpretation of self-attention, which is one of the fundamental underlying components of BERT. Using a subset of GLUE tasks and a set of handcrafted features-of-interest, we propose the methodology and carry out a qualitative and quantitative analysis of the information encoded by the individual BERT’s heads. Our findings suggest that there is a limited set of attention patterns that are repeated across different heads, indicating the overall model overparametrization. While different heads consistently use the same attention patterns, they have varying impact on performance across different tasks. We show that manually disabling attention in certain heads leads to a performance improvement over the regular fine-tuned BERT models.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="RogersHosurAnanthakrishnaEtAl_2018_Whats_in_Your_Embedding_And_How_It_Predicts_Task_Performance"><b>Rogers, A.</b>, Hosur Ananthakrishna, S., &amp; Rumshisky, A. (2018). What’s in Your Embedding, And How It Predicts Task Performance. <i>Proceedings of the 27th International Conference on Computational Linguistics</i>, 2690–2703. Santa Fe, New Mexico, USA, August 20-26, 2018: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersHosurAnanthakrishnaEtAl_2018_Whats_in_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/C18-1228'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://ldtoolkit.space'">CODE</button>
    

    

    

    

    

    

    

    
    <div class="abstract" id='RogersHosurAnanthakrishnaEtAl_2018_Whats_in_abs'>Attempts to find a single technique for general-purpose intrinsic evaluation of word embeddings have so far not been successful. We present a new approach based on scaled-up qualitative analysis of word vector neighborhoods that quantifies interpretable characteristics of a given model (e.g. its preference for synonyms or shared morphological forms as nearest neighbors). We analyze 21 such factors and show how they correlate with performance on 14 extrinsic and intrinsic task datasets (and also explain the lack of correlation between some of them). Our approach enables multi-faceted evaluation, parameter search, and generally – a more principled, hypothesis-driven approach to development of distributional semantic representations.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="RogersRomanovEtAl_2018_RuSentiment_Enriched_Sentiment_Analysis_Dataset_for_Social_Media_in_Russian"><b>Rogers, A.</b>, Romanov, A., Rumshisky, A., Volkova, S., Gronas, M., &amp; Gribov, A. (2018). RuSentiment: An Enriched Sentiment Analysis Dataset for Social Media in Russian. <i>Proceedings of the 27th International Conference on Computational Linguistics</i>, 755–763. Santa Fe, New Mexico, USA: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersRomanovEtAl_2018_RuSentiment_Enriched_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/C18-1064'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/text-machine-lab/rusentiment_baselines'">CODE</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://text-machine.cs.uml.edu/lab2/projects/rusentiment/'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id='RogersRomanovEtAl_2018_RuSentiment_Enriched_abs'>This paper presents RuSentiment, a new dataset for sentiment analysis of social media posts in Russian, and a new set of comprehensive annotation guidelines that are extensible to other languages. RuSentiment is currently the largest in its class for Russian, with 31,185 posts annotated with Fleiss’ kappa of 0.58 (3 annotations per post). To diversify the dataset, 6,950 posts were pre-selected with an active learning-style strategy. We report baseline classification results, and we also release the best-performing embeddings trained on 3.2B tokens of Russian VKontakte posts.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="LiLiuEtAl_2017_Investigating_different_syntactic_context_types_and_context_representations_for_learning_word_embeddings">Li, B., Liu, T., Zhao, Z., Tang, B., Drozd, A., <b>Rogers, A.</b>, &amp; Du, X. (2017). Investigating Different Syntactic Context Types and Context Representations for Learning Word Embeddings. <i>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</i>, 2411–2421. Copenhagen, Denmark, September 7–11, 2017.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('LiLiuEtAl_2017_Investigating_different_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/D17-1257'">PDF</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.readthedocs.io/en/docs/tutorial/getting_vectors.html#pre-trained-vsms'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id='LiLiuEtAl_2017_Investigating_different_abs'>The number of word embedding models is growing every year. Most of them are based on the co-occurrence information of words and their contexts. However, it is still an open question what is the best definition of context. We provide a systematical investigation of 4 different syntactic context types and context representations for learning word embeddings. Comprehensive experiments are conducted to evaluate their effectiveness on 6 extrinsic and intrinsic tasks. We hope that this paper, along with the published code, would be helpful for choosing the best context type and representation for a given task.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    
    :newspaper: :large_orange_diamond:
    

    

    

    

    <span id="DrozdGladkovaEtAl_2016_Word_embeddings_analogies_and_machine_learning_beyond_king_-_man_woman_queen">Drozd, A., <b>Gladkova, A.</b>, &amp; Matsuoka, S. (2016). Word Embeddings, Analogies, and Machine Learning: Beyond King - Man + Woman = Queen. <i>Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</i>, 3519–3530. Osaka, Japan, December 11-17.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/C/C16/C16-1332.pdf'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/vecto-ai/vecto/'">CODE</button>
    

    

    

    

    

    

    

    
</div>



    
</li></ol>

## Other conference and workshop articles

<ol class="bibliography"><li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="puccetti2022">Puccetti, G., <b>Rogers, A.</b>, Drozd, A., &amp; Dell’Orletta, F. (2022). Outliers Dimensions that Disrupt Transformers Are Driven by Frequency. <i>Findings of EMNLP 2022</i>. Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('puccetti2022_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.findings-emnlp.93/'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/gpucce/outliersvsfreq/tree/main'">CODE</button>
    

    

    

    

    

    

    

    
    <div class="abstract" id='puccetti2022_abs'>Transformer-based language models are known to display anisotropic behavior: the token embeddings are not homogeneously spread in space,
  but rather accumulate along certain directions. A related recent finding is the outlier phenomenon: the parameters in the final element of Transformer
  layers that consistently have unusual magnitude in the same dimension across the model, and significantly degrade its performance if disabled.
  We replicate the evidence for the outlier phenomenon and we link it to the geometry of the embedding space. Our main finding is that in both BERT and RoBERTa
  the token frequency, known to contribute to anisotropicity, also contributes to the outlier phenomenon. In its turn, the outlier phenomenon contributes to the
  ’vertical’ self-attention pattern that enables the model to focus on the special tokens. We also find that, surprisingly, the outlier effect on the model
   performance varies by layer, and that variance is also related to the correlation between outlier magnitude and encoded token frequency.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="BhargavaDrozdEtAl_2021_Generalization_in_NLI_Ways_Not_To_Go_Beyond_Simple_Heuristics">Bhargava, P., Drozd, A., &amp; <b>Rogers, A.</b> (2021). Generalization in NLI: Ways (Not) To Go Beyond Simple Heuristics. <i>Proceedings of the Second Workshop on Insights from Negative Results in NLP</i>, 125–135. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('BhargavaDrozdEtAl_2021_Generalization_in_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.insights-1.18'">PDF</button>
    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://github.com/prajjwal1/generalize_lm_nli'">CODE</button>
    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.insights-1.18.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id='BhargavaDrozdEtAl_2021_Generalization_in_abs'>Much of recent progress in NLU was shown to be due to models’ learning dataset-specific heuristics. We conduct a case study of generalization in NLI (from MNLI to the adversarially constructed HANS dataset) in a range of BERT-based architectures (adapters, Siamese Transformers, HEX debiasing), as well as with subsampling the data and increasing the model size. We report 2 successful and 3 unsuccessful strategies, all providing insights into how Transformer-based models learn to generalize.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="RogersBaldwinEtAl_2021_Just_What_do_You_Think_Youre_Doing_Dave_Checklist_for_Responsible_Data_Use_in_NLP"><b>Rogers, A.</b>, Baldwin, T., &amp; Leins, K. (2021). Just What Do You Think You’re Doing, Dave? A Checklist for Responsible Data Use in NLP. <i>Findings of the Association for Computational Linguistics: EMNLP 2021</i>, 4821–4833. Punta Cana, Dominican Republic: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersBaldwinEtAl_2021_Just_What_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-emnlp.414/'">PDF</button>
    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-emnlp.414.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id='RogersBaldwinEtAl_2021_Just_What_abs'>A key part of the NLP ethics movement is responsible use of data, but exactly what that means or how it can be best achieved remain unclear. This position paper discusses the core legal and ethical principles for collection and sharing of textual data, and the tensions between them. We propose a potential checklist for responsible data (re-)use that could both standardise the peer review of conference submissions, as well as enable a more in-depth view of published research across the community. Our proposal aims to contribute to the development of a consistent standard for data (re-)use, embraced across NLP conferences.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="GonzalezRogersEtAl_2021_On_Interaction_of_Belief_Bias_and_Explanations">González, A. V., <b>Rogers, A.</b>, &amp; Søgaard, A. (2021). On the Interaction of Belief Bias and Explanations. <i>Findings of ACL-IJCNLP 2021</i>, 2930–2942. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('GonzalezRogersEtAl_2021_On_Interaction_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-acl.259'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='GonzalezRogersEtAl_2021_On_Interaction_abs'>A myriad of explainability methods have been proposed in recent years, but there is little consensus on how to evaluate them. While automatic metrics allow for quick benchmarking, it isn’t clear how such metrics reflect human interaction with explanations. Human evaluation is of paramount importance, but previous protocols fail to account for belief biases affecting human performance, which may lead to misleading conclusions. We provide an overview of belief bias, its role in human evaluation, and ideas for NLP practitioners on how to account for it. For two experimental paradigms, we present a case study of gradient-based explainability introducing simple ways to account for humans’ prior beliefs: models of varying quality and adversarial examples. We show that conclusions about the highest performing methods change when introducing such controls, pointing to the importance of accounting for belief bias in evaluation.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="KovalevaKulshreshthaEtAl_2021_BERT_Busters_Outlier_Dimensions_that_Disrupt_Transformersa">Kovaleva, O., Kulshreshtha, S., <b>Rogers, A.</b>, &amp; Rumshisky, A. (2021). BERT Busters: Outlier Dimensions That Disrupt Transformers. <i>Findings of ACL-IJCNLP 2021</i>, 3392–3405. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KovalevaKulshreshthaEtAl_2021_BERT_Busters_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-acl.300'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://text-machine-lab.github.io/blog/2021/busters'">BLOG</button>
    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.findings-acl.300.mp4'">VIDEO</button>
    

    

    

    
    <div class="abstract" id='KovalevaKulshreshthaEtAl_2021_BERT_Busters_abs'>Multiple studies have shown that Transformers are remarkably robust to pruning. Contrary to this received wisdom, we demonstrate that pre-trained Transformer encoders are surprisingly fragile to the removal of a very small number of features in the layer outputs (<0.0001% of model weights). In case of BERT and other pre-trained encoder Transformers, the affected component is the scaling factors and biases in the LayerNorm. The outliers are high-magnitude normalization parameters that emerge early in pre-training and show up consistently in the same dimensional position throughout the model. We show that disabling them significantly degrades both the MLM loss and the downstream task performance. This effect is observed across several BERT-family models and other popular pre-trained Transformer architectures, including BART, XLNet and ELECTRA; we also show a similar effect in GPT-2.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="RogersAugenstein_2020_What_Can_We_Do_to_Improve_Peer_Review_in_NLP"><b>Rogers, A.</b>, &amp; Augenstein, I. (2020). What Can We Do to Improve Peer Review in NLP? <i>Findings of EMNLP</i>, 1256–1262. Online: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersAugenstein_2020_What_Can_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/2020.findings-emnlp.112/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='RogersAugenstein_2020_What_Can_abs'>Peer review is our best tool for judging the quality of conference submissions, but it is becoming increasingly spurious. We argue that a part of the problem is that the reviewers and area chairs face a poorly defined task forcing apples-to-oranges comparisons. There are several potential ways forward, but the key difficulty is creating the incentives and mechanisms for their consistent implementation in the NLP community.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="RogersKovalevaEtAl_2019_Calls_to_Action_on_Social_Media_Potential_for_Censorship_and_Social_Impact"><b>Rogers, A.</b>, Kovaleva, O., &amp; Rumshisky, A. (2019). Calls to Action on Social Media: Potential for Censorship and Social Impact. <i>EMNLP-IJCNLP 2019 Second Workshop on Natural Language Processing for Internet Freedom</i>.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersKovalevaEtAl_2019_Calls_to_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/D19-5005'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='RogersKovalevaEtAl_2019_Calls_to_abs'>Calls to action on social media are known to be effective means of mobilization in social movements, and a frequent target of censorship. We investigate the possibility of their automatic detection and their potential for predicting real-world protest events, on historical data of Bolotnaya protests in Russia (2011-2013). We find that political calls to action can be annotated and detected with relatively high accuracy, and that in our sample their volume has a moderate positive correlation with rally attendance.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="KarpinskaLiEtAl_2018_Subcharacter_Information_in_Japanese_Embeddings_When_Is_It_Worth_It">Karpinska, M., Li, B., <b>Rogers, A.</b>, &amp; Drozd, A. (2018). Subcharacter Information in Japanese Embeddings: When Is It Worth It? <i>Proceedings of the Workshop on the Relevance of Linguistic Structure in Neural Architectures for NLP</i>, 28–37. Melbourne, Australia: ACL.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KarpinskaLiEtAl_2018_Subcharacter_Information_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://aclweb.org/anthology/W18-2905'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/jBATS/'">BLOG</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/jBATS/'">CODE</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/jBATS/'">DATA</button>
    

    

    

    

    

    

    
    <div class="abstract" id='KarpinskaLiEtAl_2018_Subcharacter_Information_abs'>Languages with logographic writing systems present a difficulty for traditional character-level models. Leveraging the subcharacter information was recently shown to be beneficial for a number of intrinsic and extrinsic tasks in Chinese. We examine whether the same strategies could be applied for Japanese, and contribute a new analogy dataset for this language.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="RogersDrozdEtAl_2017_Too_Many_Problems_of_Analogical_Reasoning_with_Word_Vectors"><b>Rogers, A.</b>, Drozd, A., &amp; Li, B. (2017). The (Too Many) Problems of Analogical Reasoning with Word Vectors. <i>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (* SEM 2017)</i>, 135–148.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('RogersDrozdEtAl_2017_Too_Many_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.aclweb.org/anthology/S17-1017'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='RogersDrozdEtAl_2017_Too_Many_abs'>This paper explores the possibilities of analogical reasoning with vector space models. Given two pairs of words with the same relation (e.g. man:woman :: king:queen), it was proposed that the offset between one pair of the corresponding word vectors can be used to identify the unknown member of the other pair (king - man + woman = queen). We argue against such “linguistic regularities” as a model for linguistic relations in vector space models and as a benchmark, and we show that the vector offset (as well as two other, better-performing methods) suffers from dependence on vector similarity.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="GladkovaDrozd_2016_Intrinsic_evaluations_of_word_embeddngs_what_can_we_do_better"><b>Gladkova, A.</b>, &amp; Drozd, A. (2016). Intrinsic Evaluations of Word Embeddings: What Can We Do Better? <i>Proceedings of The 1st Workshop on Evaluating Vector Space Representations for NLP</i>, 36–42. https://doi.org/10.18653/v1/W16-2507</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.aclweb.org/anthology/W/W16/W16-2507.pdf'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="GladkovaDrozdEtAl_2016_Analogy-based_detection_of_morphological_and_semantic_relations_with_word_embeddings_what_works_and_what_doesnt"><b>Gladkova, A.</b>, Drozd, A., &amp; Matsuoka, S. (2016). Analogy-Based Detection of Morphological and Semantic Relations with Word Embeddings: What Works and What Doesn’t. <i>Proceedings of the NAACL-HLT SRW</i>, 47–54. https://doi.org/10.18653/v1/N16-2002</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/N/N16/N16-2002.pdf'">PDF</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/BATS/'">BLOG</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/BATS/'">CODE</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://vecto.space/projects/BATS/'">DATA</button>
    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="DrozdGladkovaEtAl_2015_Discovering_aspectual_classes_of_Russian_verbs_in_untagged_large_corpora">Drozd, A., <b>Gladkova, A.</b>, &amp; Matsuoka, S. (2015). Discovering Aspectual Classes of Russian Verbs in Untagged Large Corpora. <i>Proceedings of 2015 IEEE International Conference on Data Science and Data Intensive Systems (DSDIS)</i>, 61–68. https://doi.org/10.1109/DSDIS.2015.30</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('DrozdGladkovaEtAl_2015_Discovering_aspectual_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.ieeexplore.ieee.org/document/7396482/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='DrozdGladkovaEtAl_2015_Discovering_aspectual_abs'>This paper presents a case study of discovering and classifying verbs in large web-corpora. Many tasks in natural language processing require corpora containing billions of words, and with such volumes of data co-occurrence extraction becomes one of the performance bottlenecks in the Vector Space Models of computational linguistics. We propose a co-occurrence extraction kernel based on ternary trees as an alternative (or a complimentary stage) to conventional map-reduce based approach, this kernel achieves an order of magnitude improvement in memory footprint and processing speed. Our classifier successfully and efficiently identified verbs in a 1.2-billion words untagged corpus of Russian fiction and distinguished between their two aspectual classes. The model proved efficient even for low-frequency vocabulary, including nonce verbs and neologisms.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    
    :newspaper:
    

    

    

    

    

    <span id="DrozdGladkovaEtAl_2015_Python_performance_and_Natural_Language_Processing">Drozd, A., <b>Gladkova, A.</b>, &amp; Matsuoka, S. (2015). Python, Performance, and Natural Language Processing. <i>Proceedings of the 5th Workshop on Python for High-Performance and Scientific Computing</i>, 1:1–1:10. https://doi.org/10.1145/2835857.2835858</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('DrozdGladkovaEtAl_2015_Python_performance_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://dl.acm.org/citation.cfm?id=2835858'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='DrozdGladkovaEtAl_2015_Python_performance_abs'>We present a case study of Python-based workflow for a data-intensive natural language processing problem, namely word classification with vector space model methodology. Problems in the area of natural language processing are typically solved in many steps which require transformation of the data to vastly different formats (in our case, raw text to sparse matrices to dense vectors). A Python implementation for each of these steps would require a different solution. We survey existing approaches to using Python for high-performance processing of large volumes of data, and we propose a sample solution for each step for our case study (aspectual classification of Russian verbs), attempting to preserve both efficiency and user-friendliness. For the most computationally intensive part of the workflow we develop a prototype distributed implementation of co-occurrence extraction module using IPython.parallel cluster.</div>
    
</div>



    
</li></ol>

## Non-peer-reviewed publications

<ol class="bibliography"><li><div class="text-justify">

    

    

    

    
    :black_nib:
    

    

    

    <span id="KuznetsovAfzalEtAl_2024_What_Can_Natural_Language_Processing_Do_for_Peer_Review">Kuznetsov, I., Afzal, O. M., Dercksen, K., Dycke, N., Goldberg, A., Hope, T., … Gurevych, I. (2024). <i>What Can Natural Language Processing Do for Peer Review?</i> arXiv.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('KuznetsovAfzalEtAl_2024_What_Can_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://arxiv.org/abs/2405.06563'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='KuznetsovAfzalEtAl_2024_What_Can_abs'>The number of scientific articles produced every year is growing rapidly. Providing quality control over them is crucial for scientists and, ultimately, for the public good. In modern science, this process is largely delegated to peer review – a distributed procedure in which each submission is evaluated by several independent experts in the field. Peer review is widely used, yet it is hard, time-consuming, and prone to error. Since the artifacts involved in peer review – manuscripts, reviews, discussions – are largely text-based, Natural Language Processing has great potential to improve reviewing. As the emergence of large language models (LLMs) has enabled NLP assistance for many new tasks, the discussion on machine-assisted peer review is picking up the pace. Yet, where exactly is help needed, where can NLP help, and where should it stand aside? The goal of our paper is to provide a foundation for the future efforts in NLP for peer-reviewing assistance. We discuss peer review as a general process, exemplified by reviewing at AI conferences. We detail each step of the process from manuscript submission to camera-ready revision, and discuss the associated challenges and opportunities for NLP assistance, illustrated by existing work. We then turn to the big challenges in NLP for peer review as a whole, including data acquisition and licensing, operationalization and experimentation, and ethical issues. To help consolidate community efforts, we create a companion repository that aggregates key datasets pertaining to peer review. Finally, we issue a detailed call for action for the scientific community, NLP and AI researchers, policymakers, and funding bodies to help bring the research in NLP for peer review forward. We hope that our work will help set the agenda for research in machine-assisted scientific quality control in the age of AI, within the NLP community and beyond.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    

    
    :black_nib:
    

    

    

    <span id="LuccioniRogers_2023_Mind_your_Language_Model_FactChecking_LLMs_and_their_Role_in_NLP_Research_and_Practice">Luccioni, A. S., &amp; <b>Rogers, A.</b> (2023). <i>Mind Your Language (Model): Fact-Checking LLMs and Their Role in NLP Research and Practice</i>. arXiv (under review).</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('LuccioniRogers_2023_Mind_your_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'http://arxiv.org/abs/2308.07120'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='LuccioniRogers_2023_Mind_your_abs'>Much of the recent discourse within the NLP research community has been centered around Large Language Models (LLMs), their functionality and potential – yet not only do we not have a working definition of LLMs, but much of this discourse relies on claims and assumptions that are worth re-examining. This position paper contributes a definition of LLMs, explicates some of the assumptions made regarding their functionality, and outlines the existing evidence for and against them. We conclude with suggestions for research directions and their framing in future work.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    

    
    :black_nib:
    

    

    

    <span id="rogers-etal-2023-report"><b>Rogers, A.</b>, Karpinska, M., Boyd-Graber, J., &amp; Okazaki, N. (2023). Program Chairs’ Report on Peer Review at ACL 2023. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('rogers-etal-2023-report_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-long.report'">PDF</button>
    

    

    

    

    

    

    

    

    

    
    <div class="abstract" id='rogers-etal-2023-report_abs'>We present a summary of the efforts to improve conference peer review that were implemented at ACL’23. This includes work with the goal of improving review quality, clearer workflow and decision support for the area chairs, as well as our efforts to improve paper-reviewer matching for various kinds of non- mainstream NLP work, and improve the overall incentives for all participants of the peer review process. We present analysis of the factors affecting peer review, identify the most problematic issues that the authors complained about, and provide suggestions for the future chairs. We hope that publishing such reports would (a) improve transparency in decision-making, (b) help the people new to the field to understand how the *ACL conferences work, (c) provide useful data for the future chairs and workshop organizers, and also academic work on peer review, and (d) provide useful context for the final program, as a source of information for meta-research on the structure and trajectory of the field of NLP.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    

    
    :black_nib:
    

    

    

    <span id="ScaoFanEtAl_2022_BLOOM_176BParameter_OpenAccess_Multilingual_Language_Model">Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., … Wolf, T. (2022). <i>BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</i>. arxiv.</span>

    
    

    

    
    <button class="btn--info" onclick="showBibtex('ScaoFanEtAl_2022_BLOOM_176BParameter_abs')">Abstract</button>
    

    
    <button class="btn--success" onclick="window.location.href = 'https://arxiv.org/abs/2211.05100'">PDF</button>
    

    

    

    

    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://huggingface.co/bigscience/bloom'">DEMO</button>
    

    

    
    <div class="abstract" id='ScaoFanEtAl_2022_BLOOM_176BParameter_abs'>Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.</div>
    
</div>



    
</li>
<li><div class="text-justify">

    

    

    

    
    :black_nib:
    

    

    

    <span id="SantusGladkovaEtAl_2016_CogALex-V_shared_task_on_corpus-based_identification_of_semantic_relations">Santus, E., <b>Gladkova, A.</b>, Evert, S., &amp; Lenci, A. (2016). The CogALex-V Shared Task on the Corpus-Based Identification of Semantic Relations. Osaka, Japan, December 11-17: ACL.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'http://www.aclweb.org/anthology/W/W16/W16-53.pdf#page=83'">PDF</button>
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://sites.google.com/site/cogalex2016/home/shared-task'">DATA</button>
    

    

    

    

    

    

    
</div>



    
</li></ol>

## Edited volumes

<ol class="bibliography"><li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="insights-2024-insights">Tafreshi, S., Akula, A., Sedoc, J., Drozd, A., <b>Rogers, A.</b>, &amp; Rumshisky, A. (Eds.). (2024). <i>Proceedings of the Fifth Workshop on Insights from Negative Results in NLP</i>. Mexico City, Mexico: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2024.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="acl-2023-frontmatter"><b>Rogers, A.</b>, Boyd-Graber, J., &amp; Okazaki, N. (Eds.). (2023). <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-long.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="acl-2023-short-frontmatter"><b>Rogers, A.</b>, Boyd-Graber, J., &amp; Okazaki, N. (Eds.). (2023). <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.acl-short.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="findings-2023-findings-association"><b>Rogers, A.</b>, Boyd-Graber, J., &amp; Okazaki, N. (Eds.). (2023). <i>Findings of the Association for Computational Linguistics: ACL 2023</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.findings-acl.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="repl4nlp-2023-representation">Can, B., Mozes, M., Cahyawijaya, S., Saphra, N., Kassner, N., Ravfogel, S., … Voita, L. (Eds.). (2023). <i>Proceedings of the 8th Workshop on Representation Learning for NLP (RepL4NLP 2023)</i>. Toronto, Canada: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.repl4nlp-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="insights-2023-insights">Tafreshi, S., Akula, A., Sedoc, J., Drozd, A., <b>Rogers, A.</b>, &amp; Rumshisky, A. (Eds.). (2023). <i>The Fourth Workshop on Insights from Negative Results in NLP</i>. Dubrovnik, Croatia: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2023.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="insights-2022-insights">Tafreshi, S., Sedoc, J., <b>Rogers, A.</b>, Drozd, A., Rumshisky, A., &amp; Akula, A. (Eds.). (2022). <i>Proceedings of the Third Workshop on Insights from Negative Results in NLP</i>. Dublin, Ireland: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="repl4nlp-2022-representation">Gella, S., He, H., Majumder, B. P., Can, B., Giunchiglia, E., Cahyawijaya, S., … Dyer, C. (Eds.). (2022). <i>Proceedings of the 7th Workshop on Representation Learning for NLP</i>. Dublin, Ireland: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2022.repl4nlp-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="insights-2021-insights">Sedoc, J., <b>Rogers, A.</b>, Rumshisky, A., &amp; Tafreshi, S. (Eds.). (2021). <i>Proceedings of the Second Workshop on Insights from Negative Results in NLP</i>. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="repl4nlp-2021-representation"><b>Rogers, A.</b>, Calixto, I., Vulić, I., Saphra, N., Kassner, N., Camburu, O.-M., … Shwartz, V. (Eds.). (2021). <i>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</i>. Online: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2021.repl4nlp-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="insights-2020-insights"><b>Rogers, A.</b>, Sedoc, J., &amp; Rumshisky, A. (Eds.). (2020). <i>Proceedings of the First Workshop on Insights from Negative Results in NLP</i>. Online: Association for Computational Linguistics.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://aclanthology.org/2020.insights-1.0'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li>
<li><div class="text-justify">

    
    :notebook:
    

    

    

    

    

    

    <span id="RogersDrozdEtAl_2019_Proceedings_of_3rd_Workshop_on_Evaluating_Vector_Space_Representations_for_NLP"><b>Rogers, A.</b>, Drozd, A., Rumshisky, A., &amp; Goldberg, Y. (2019). <i>Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP</i>.</span>

    
    

    

    

    
    <button class="btn--success" onclick="window.location.href = 'https://www.aclweb.org/anthology/papers/W/W19/W19-2000/'">PDF</button>
    

    

    

    

    

    

    

    

    

    
</div>



    
</li></ol>

-->

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    <!--li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li-->
  </ul>
</div>

<div class="page__footer-copyright">© 2024 Anna Rogers. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.
  <!--a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a-->This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>













  </body>
</html>
